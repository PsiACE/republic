# Chat

`llm.chat(...)` is the smallest entry point and fits most text-only workloads.

## Prompt Mode

```python
from republic import LLM

llm = LLM(model="openrouter:openrouter/free", api_key="<API_KEY>")
out = llm.chat("Output exactly one word: ready", max_tokens=8)
print(out)
```

## Messages Mode

```python
messages = [
    {"role": "system", "content": "Be concise."},
    {"role": "user", "content": "Explain tape-first in one sentence."},
]
out = llm.chat(messages=messages, max_tokens=48)
```

## Transport Format (`api_format`)

Republic exposes one public chat/tool/stream interface, and lets you choose the upstream API format explicitly:

- `api_format="completion"` (default): chat-completions style.
- `api_format="responses"`: responses style.
- `api_format="messages"`: Anthropic messages style (only Anthropic models, including `openrouter:anthropic/...`).

```python
llm_completion = LLM(model="openai:gpt-4o-mini", api_key="<OPENAI_KEY>", api_format="completion")
llm_responses = LLM(model="openrouter:openrouter/free", api_key="<OPENROUTER_KEY>", api_format="responses")
llm_messages = LLM(model="openrouter:anthropic/claude-3.5-haiku", api_key="<OPENROUTER_KEY>", api_format="messages")
```

The same public methods are used in all formats: `chat`, `tool_calls`, `run_tools`, `stream`, and `stream_events`.

## Retries and Fallback

```python
llm = LLM(
    model="openai:gpt-4o-mini",
    fallback_models=["anthropic:claude-3-5-sonnet-latest"],
    max_retries=3,
    api_key={"openai": "<OPENAI_KEY>", "anthropic": "<ANTHROPIC_KEY>"},
)

out = llm.chat("Give me one deployment checklist item.")
```

Recommendation: keep `max_retries` small (for example 2-4), and pick fallback models that are slightly more stable while still meeting quality requirements.
